{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "\n",
    "For this lab, you will have to implement your own perceptron learner. There are available implementations from libraries such as sklearn (see code below), but writing your own omplementation will help with understanding. You can write your code in a different language if you don't feel comfortable with Python. \n",
    "\n",
    "For this lab, you won't need to update the weights following the stochastic gradient descent. You will add or deduct 1 for each weight as appropriate. \n",
    "\n",
    "<img src=\"image.jpg\" alt=\"Drawing\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Activation \n",
    "\n",
    "First of all you will need an activation function, that takes as input the inputs x_i and the weights and calculates a weighted sum. The weighted sum of two vectors can be thought of as their dot product (since vectors can be thought of as single column arrays/matrices). For instance: \n",
    "\n",
    "a = [1,2,3]\n",
    "\n",
    "b = [2,0,3]\n",
    "\n",
    "weighted_sum = np.dot(a,b)\n",
    "\n",
    "The numpy library makes it easy to do mathematical operations on arrays: https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html\n",
    "\n",
    "Then the weighted sum should be checked and if it is greater or equal to 0, the activation function should predict the class 1, otherwise it should predict the class 0. \n",
    "\n",
    "Finally, the function should return 1 if the weighted sum is positive, otherwise 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(inputs_x, weights_w):\n",
    "    \n",
    "    #calculate weighted sum here:\n",
    "    weighted_sum = \n",
    "    \n",
    "    #check whether the sum is positive or not and return 1 if it is positive and 0 if it is not\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Weights Update\n",
    "\n",
    "Secondly, you need a function that takes as input the features of an instance inputs_x, the weights_w and the a constant number: 1 if the weights needs to be updated by 1, and -1 if the weights need to be reduced by 1. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(inputs_x, weights_w, update_num):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perceptron learning \n",
    "\n",
    "Finally, consider the following data. data_x includes the features, and data_y the variable we want to predict. \n",
    "Write a function \"perceptron\" that takes as input data_x, data_y, and weights and updates the weights accordingly. \n",
    "\n",
    "Note for this exercise you don't have to use a learning rate and stochastic gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data. Each row corresponds to an instance, and the last column contains the variable we won't to predict. \n",
    "data_x = np.array([[1,1,0,1],\n",
    "[0,0,1,0],\n",
    "[1,0,1,1],\n",
    "[1,0,1,1],\n",
    "[0,0,1,0],\n",
    "[1,1,1,1],\n",
    "[0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = np.array([0,0,1,1,0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(data_x, data_y, weights):\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run your code and check the final weights\n",
    "perceptron(data_x, data_y, weights)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn implementation: fyi\n",
    "\n",
    "In Python, there are many libraries that you can simply use to implement any machine learning algorithms. For perceptron, see the example below from sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Colab, uncomment the code below\n",
    "\n",
    "#from google.colab import drive \n",
    "#drive.mount('/content/gdrive')\n",
    "\n",
    "#set local path where notebooks and data folders are located\n",
    "#path = \"/content/gdrive/My Drive/DW_data/\"\n",
    "#data_path = path + \"zoo.data\"\n",
    "#print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "import pandas as pd\n",
    "\n",
    "#Import the dataset (dropped the first column with the animal names)\n",
    "dataset = pd.read_csv('zoo.data', header=None, usecols=[*range(1, 18)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into a training and a testing set\n",
    "train_features = dataset.iloc[:80,:-1]\n",
    "test_features = dataset.iloc[80:,:-1]\n",
    "train_labels = dataset.iloc[:80,-1]\n",
    "test_labels = dataset.iloc[80:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron(tol=1e-3, random_state=0)\n",
    "perceptron.fit(train_features, train_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron.score(test_features, test_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you'd use that in an application that takes data in real-time, you'd use the predict function to make predictions\n",
    "#Firstly, we need to get the prediction on the test set as follows\n",
    "prediction = perceptron.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
